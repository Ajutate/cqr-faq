# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# LLM Model - Recommended models for accurate data extraction (less hallucination):
# mistral - BEST for structured data extraction (Recommended!)
# llama3 - Most capable and accurate
# phi3 - Fast and good for factual extraction
# llama2 - General purpose (more prone to hallucination)
OLLAMA_MODEL=llama2

# Embedding Model - Use Ollama embeddings for consistency
# nomic-embed-text - RECOMMENDED (Fast, accurate, 768 dimensions)
# mxbai-embed-large - High quality (1024 dimensions)
# all-minilm - Smaller, faster (384 dimensions)
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# First time setup:
# 1. Pull LLM model: ollama pull llama2 (or mistral for better accuracy)
# 2. Pull embedding model: ollama pull nomic-embed-text

# To switch models, first pull: ollama pull mistral
# Then change OLLAMA_MODEL=mistral

# ChromaDB Configuration
CHROMA_PERSIST_DIRECTORY=./chroma_db

# Application Configuration
UPLOAD_FOLDER=./uploads
